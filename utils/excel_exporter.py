import pandas as pd
import streamlit as st
from io import BytesIO
from typing import List, Dict
import json


def create_excel_from_data(extracted_data: List[Dict]) -> BytesIO:
    """
    Cr√©e un fichier Excel √† partir des donn√©es extraites.

    Args:
        extracted_data: Liste de dictionnaires contenant les donn√©es extraites

    Returns:
        BytesIO: Fichier Excel en m√©moire
    """
    try:
        # Cr√©er un DataFrame √† partir des donn√©es
        df = pd.DataFrame(extracted_data)

        # Cr√©er un buffer en m√©moire
        excel_buffer = BytesIO()

        # Cr√©er le fichier Excel
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Extracted_Data', index=False)

            # Ajuster la largeur des colonnes
            worksheet = writer.sheets['Extracted_Data']
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter

                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass

                adjusted_width = min(max_length + 2, 50)  # Maximum 50 caract√®res
                worksheet.column_dimensions[column_letter].width = adjusted_width

        excel_buffer.seek(0)
        return excel_buffer

    except Exception as e:
        st.error(f"Erreur lors de la cr√©ation du fichier Excel : {str(e)}")
        return None


def validate_and_clean_data(raw_data: str) -> List[Dict]:
    """
    Valide et nettoie les donn√©es JSON re√ßues de Groq.
    """
    try:
        # Supprimer balises Markdown √©ventuelles
        if raw_data.startswith("```json"):
            raw_data = raw_data.replace("```json", "").replace("```", "").strip()

        # Corriger √©chappements invalides (\n, \t, \u etc.)
        raw_data = raw_data.replace("\\n", " ").replace("\\t", " ").replace("\\r", " ")

        # Parser le JSON de mani√®re robuste
        parsed_data = json.loads(raw_data)

        if isinstance(parsed_data, dict):
            parsed_data = [parsed_data]

        required_fields = ["Company", "Product Group", "Country", "Address", "Phone", "Email", "Website", "Brands"]
        cleaned_data = []

        for entry in parsed_data:
            cleaned_entry = {}
            for field in required_fields:
                value = entry.get(field, "N/A")
                if not value or str(value).lower() in ["null", "none", ""]:
                    cleaned_entry[field] = "N/A"
                else:
                    cleaned_entry[field] = str(value).strip()
            cleaned_data.append(cleaned_entry)

        return cleaned_data

    except json.JSONDecodeError as e:
        st.error(f"Erreur de parsing JSON : {str(e)}")
        st.error(f"‚ö†Ô∏è Donn√©es re√ßues (extrait) : {raw_data[:500]}...")
        return []
    except Exception as e:
        st.error(f"Erreur lors du nettoyage des donn√©es : {str(e)}")
        return []



def display_preview(data: List[Dict]):
    """
    Affiche un aper√ßu des donn√©es extraites dans Streamlit.

    Args:
        data: Donn√©es √† afficher
    """
    if not data:
        st.warning("Aucune donn√©e √† afficher.")
        return

    st.subheader("üìä Aper√ßu des donn√©es extraites")

    # Cr√©er un DataFrame pour l'affichage
    df = pd.DataFrame(data)

    # Afficher les statistiques
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Nombre d'entreprises", len(data))
    with col2:
        completed_fields = sum(1 for entry in data for value in entry.values() if value != "N/A")
        total_fields = len(data) * len(data[0]) if data else 0
        completion_rate = (completed_fields / total_fields * 100) if total_fields > 0 else 0
        st.metric("Taux de compl√©tion", f"{completion_rate:.1f}%")
    with col3:
        unique_countries = len(set(entry.get("Country", "N/A") for entry in data if entry.get("Country") != "N/A"))
        st.metric("Pays uniques", unique_countries)

    # Afficher le tableau
    st.dataframe(df, use_container_width=True)